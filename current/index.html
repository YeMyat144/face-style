<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="icon" href="/current/jojo.png" type="image/png">
    <link rel="stylesheet" href="/current/style.css">
    <title>JoJo Real-Time Face Stylization</title>
    
</head>
<body>
    <div>
        <h1>Real-Time Face Stylization</h1>
        <div id="imageContainer">
            <h2>Image Transformation</h2>
            <input type="file" id="inputImage" accept="image/*" />
            <button id="transformButton">Submit</button><br><br>
            <div id="outputImageContainer">
                <h3>Output Image:</h3>
                <img width="256" height="256" id="outputImage" alt="Result"/>
            </div>
        </div>
        
        <div id="videoContainer">
            <h2>Real-Time Video</h2>
            <button id="startVideo">Start</button>
            <button id="stopVideo" style="display: none;">Stop</button><br><br>
            <div id="container" style="display: flex">
                <video id="webcam" autoplay ></video>
                <canvas id="outputCanvas" autoplay></canvas>
            </div>
        </div>
    </div>

    <script>
        document.getElementById('transformButton').addEventListener('click', async () => {
            const inputImage = document.getElementById('inputImage').files[0];
            if (!inputImage) return;

            const reader = new FileReader();
            reader.onload = (e) => {
                const img = new Image();
                img.src = e.target.result;
                img.onload = () => {
                    // Here you would process the image using your model.
                    // For simplicity, we display the input image as the "stylized" output.
                    const outputImage = document.getElementById('outputImage');
                    outputImage.src = img.src;
                };
            };
            reader.readAsDataURL(inputImage);
        });

        const startVideoButton = document.getElementById('startVideo');
        const stopVideoButton = document.getElementById('stopVideo');
        const webcam = document.getElementById('webcam');
        const outputCanvas = document.getElementById('outputCanvas');
        let videoStream;

        startVideoButton.addEventListener('click', async () => {
            videoStream = await navigator.mediaDevices.getUserMedia({ video: true });
            webcam.srcObject = videoStream;
            webcam.style.display = 'block';
            outputCanvas.style.display = 'block';
            startVideoButton.style.display = 'none';
            stopVideoButton.style.display = 'inline';

            const context = outputCanvas.getContext('2d');

            function drawFrame() {
                if (videoStream.active) {
                    context.drawImage(webcam, 0, 0, outputCanvas.width, outputCanvas.height);
                    // You would normally process the frame using your model here
                    requestAnimationFrame(drawFrame);
                }
            }

            drawFrame();
        });

        stopVideoButton.addEventListener('click', () => {
            videoStream.getTracks().forEach(track => track.stop());
            webcam.style.display = 'none';
            outputCanvas.style.display = 'none';
            startVideoButton.style.display = 'inline';
            stopVideoButton.style.display = 'none';
        });
    </script>
</body>
</html>
